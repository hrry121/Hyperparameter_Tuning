# ğŸ” Hyperparameter Tuning with Cross-Validation & MLflow Tracking

This project demonstrates hyperparameter tuning on a regression model using **Scikit-Learn's** `GridSearchCV`, evaluated with **Mean Squared Error (MSE)**, and tracked using **MLflow** for experiment management.

---

## ğŸ“Œ Project Highlights

- **Model Optimization** via Grid Search over a defined hyperparameter space  
- **Cross-Validation** with `cv=3` to ensure model generalization  
- **Metric Used**: Mean Squared Error (MSE) for evaluation  
- **Experiment Tracking** with MLflow (parameters, metrics, artifacts, and models)  
- **Best Model Selection** based on the lowest average MSE across folds

---

## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ mlruns/              # MLflow logs (auto-generated)
â”œâ”€â”€ house_prediction.py  # Script to run tuning + tracking
â”œâ”€â”€ requirements.txt     # Required packages
â””â”€â”€ README.md            # You're here!

---

## ğŸ› ï¸ Tech Stack

- Python
- Scikit-Learn  
- MLflow  
- Pandas  

---
